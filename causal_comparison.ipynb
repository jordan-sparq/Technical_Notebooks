{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Causal Methods\n",
    "\n",
    "In this notebook, we can check if our data features are causally connected or not by comparing predictive SHAP values with true causal effects. If these two are equivalent then interventions can be made based purely on SHAP values.\n",
    "If they are not equivalent, then the predictive model is not learning true causal effects, only correlations.\n",
    "\n",
    "Adapted from: https://shap.readthedocs.io/en/latest/example_notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%C2%A0insights.html\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "networkx, castle, xgboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 08:15:37,622 - /opt/miniconda3/envs/env_gal/lib/python3.9/site-packages/castle/algorithms/__init__.py[line:36] - INFO: You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "import xgboost\n",
    "\n",
    "import os\n",
    "os.environ['CASTLE_BACKEND'] = 'pytorch'\n",
    "from collections import OrderedDict\n",
    "import networkx as nx\n",
    "from castle.algorithms import PC, GES, ICALiNGAM, GOLEM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulate a fake dataset with a binary outcome"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixableDataFrame(pd.DataFrame):\n",
    "    \"\"\" Helper class for manipulating generative models.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, fixed={}, **kwargs):\n",
    "        self.__dict__[\"__fixed_var_dictionary\"] = fixed\n",
    "        super(FixableDataFrame, self).__init__(*args, **kwargs)\n",
    "    def __setitem__(self, key, value):\n",
    "        out = super(FixableDataFrame, self).__setitem__(key, value)\n",
    "        if isinstance(key, str) and key in self.__dict__[\"__fixed_var_dictionary\"]:\n",
    "            out = super(FixableDataFrame, self).__setitem__(key, self.__dict__[\"__fixed_var_dictionary\"][key])\n",
    "        return out\n",
    "\n",
    "# generate the data\n",
    "def generator(n, fixed={}, seed=0):\n",
    "    \"\"\" The generative model for our subscriber retention example.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X = FixableDataFrame(fixed=fixed)\n",
    "\n",
    "    # days to go before flight departure\n",
    "    dtg = np.random.uniform(0, 365, size=(n,)).round()\n",
    "    X[\"dtg\"] = (1/np.random.uniform(1, 2, size=(n,)).round()) * dtg\n",
    "\n",
    "    # Destination type, assume there are 3 categorical values: Beach, City, Domestic\n",
    "    X[\"Destination Type\"] = np.random.uniform(0, 2, size=(n,)).round()\n",
    "\n",
    "    # The price of the flight depends on destination type\n",
    "    X[\"Flight Price\"] = (X[\"Destination Type\"]+1)/2 *  np.random.uniform(45, 250, size=(n,))\n",
    "\n",
    "    # Range of prices shown to the customer depends on destination type\n",
    "    X[\"Range of Prices\"] = (X[\"Destination Type\"]+1) +  np.random.uniform(0, 50, size=(n,)).round()\n",
    "\n",
    "    # number of alternative flights shown depends on destination type\n",
    "    X[\"Alternative Flights\"] = (X[\"Destination Type\"]+1)  +  np.random.uniform(0, 20, size=(n,)).round()\n",
    "\n",
    "    # did the user renew?\n",
    "    X[\"Did convert\"] = scipy.special.expit((\n",
    "          0.5 / X[\"dtg\"] \\\n",
    "        + 0.5 / X[\"Flight Price\"] \\\n",
    "        + 0.15 * X[\"Destination Type\"] \\\n",
    "        + 0.2 / X[\"Range of Prices\"] \\\n",
    "        + 0.05 * X[\"Alternative Flights\"]\n",
    "        + 0.1 * np.random.normal(0, 1, size=(n,))\n",
    "    ))\n",
    "\n",
    "    # in real life we would make a random draw to get either 0 or 1 for if the\n",
    "    # customer did or did not renew. but here we leave the label as the probability\n",
    "    # so that we can get less noise in our plots. Uncomment this line to get\n",
    "    # noiser causal effect lines but the same basic results\n",
    "    X[\"Did convert\"] = scipy.stats.bernoulli.rvs(X[\"Did convert\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "def user_retention_dataset():\n",
    "    \"\"\" The observed data for model training.\n",
    "    \"\"\"\n",
    "    n = 10000\n",
    "    X_full = generator(n)\n",
    "    y = X_full[\"Did convert\"]\n",
    "    X = X_full.drop([\"Did convert\"], axis=1)\n",
    "    return X, y\n",
    "\n",
    "def fit_xgboost(X, y):\n",
    "    \"\"\" Train an XGBoost model with early stopping.\n",
    "    \"\"\"\n",
    "    X_train,X_test,y_train,y_test = sklearn.model_selection.train_test_split(X, y)\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgboost.DMatrix(X_test, label=y_test)\n",
    "    model = xgboost.train(\n",
    "        { \"eta\": 0.001, \"subsample\": 0.5, \"max_depth\": 2, \"objective\": \"reg:logistic\"}, dtrain, num_boost_round=200000,\n",
    "        evals=((dtest, \"test\"),), early_stopping_rounds=20, verbose_eval=False\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = user_retention_dataset()\n",
    "model = fit_xgboost(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SHAP values from prediction model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "clust = shap.utils.hclust(X, y, linkage=\"single\")\n",
    "shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values, ylabel=\"SHAP value\\n(higher means more likely to convert)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Approach\n",
    "\n",
    "We can see the SHAP values think that the flight price has some causal impact on conversion rate but the true causal impact is flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def marginal_effects(generative_model, num_samples=1000, columns=None, max_points=100, logit=True, seed=0):\n",
    "    \"\"\" Helper function to compute the true marginal causal effects.\n",
    "    \"\"\"\n",
    "    X = generative_model(num_samples)\n",
    "    if columns is None:\n",
    "        columns = X.columns\n",
    "    ys = [[] for _ in columns]\n",
    "    xs = [X[c].values for c in columns]\n",
    "    xs = np.sort(xs, axis=1)\n",
    "    xs = [xs[i] for i in range(len(xs))]\n",
    "    for i,c in enumerate(columns):\n",
    "        print(i, c)\n",
    "        xs[i] = np.unique([np.nanpercentile(xs[i], v, method='nearest') for v in np.linspace(0, 100, max_points)])\n",
    "        for x in xs[i]:\n",
    "            Xnew = generative_model(num_samples, fixed={c: x}, seed=seed)\n",
    "            val = Xnew[\"Did convert\"].mean()\n",
    "            if logit:\n",
    "                val = scipy.special.logit(val)\n",
    "\n",
    "            if (val == np.inf) or (val == -1 * np.inf) or (val == np.nan):\n",
    "                val = 0\n",
    "            ys[i].append(val)\n",
    "        ys[i] = np.array(ys[i])\n",
    "    ys = [ys[i] - ys[i].mean() for i in range(len(ys))]\n",
    "    return list(zip(xs, ys))\n",
    "\n",
    "shap.plots.scatter(shap_values, ylabel=\"SHAP value\\n(higher means more likely to convert)\", overlay={\n",
    "    \"True causal effects\": marginal_effects(generator, 10000, X.columns)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Discovery\n",
    "This section automatically generates causal DAGs based on observed data. You can pass in your features and target and these algorithms will try a number of different DAGs and score their relevance. This uses a number of different methods as the best one depends on the data so it is worth trying them all and seeing which seems more reasonable.\n",
    "\n",
    "Use with caution. Try first with simulated data where you know the outcome. Make this simulated data as similar to what you expect from your true data as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pc_dataset = np.vstack([X['Destination Type'], X['Alternative Flights'], X['Flight Price'], X['dtg'], y.values]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pc_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us the adjacency matrix of our features. i.e if row 0 column 1 is 1 then feature 0 is causally impacting feature 1. We can then use networkx to draw the result of this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pc = PC()\n",
    "pc.learn(pc_dataset)\n",
    "\n",
    "# Print out the learned matrix\n",
    "print(pc.causal_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get learned graph\n",
    "learned_graph = nx.DiGraph(pc.causal_matrix)\n",
    "\n",
    "# Relabel the nodes\n",
    "MAPPING = {k: v for k, v in zip(range(5), ['Destination Type', 'Alternative Flights', 'Flight Price', 'dtg', 'CvR'])}\n",
    "\n",
    "learned_graph = nx.relabel_nodes(learned_graph, MAPPING, copy=True)\n",
    "# Plot the graph\n",
    "nx.draw_networkx(\n",
    "    learned_graph,\n",
    "    with_labels=True,\n",
    "    node_size=1800,\n",
    "    font_size=18,\n",
    "    font_color='white'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now try more methods for completeness\n",
    "\n",
    "We know that the result from GOLEM and LiNGAM are quite incorrect. However, PC and GES are very close to what the simulation intended. The bidirectional arrow is alarming but this does give us a good indication of the causal impacts of our features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "methods = OrderedDict({\n",
    "    'PC': PC,\n",
    "    'GES': GES,\n",
    "    'LiNGAM': ICALiNGAM,\n",
    "    'GOLEM': GOLEM\n",
    "})\n",
    "\n",
    "for method in methods:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(f'{method}')\n",
    "    if method == 'GOLEM':\n",
    "        model = methods[method](num_iter=2.5e4)\n",
    "    else:\n",
    "        model = methods[method]()\n",
    "\n",
    "    # Fit the model\n",
    "    model.learn(pc_dataset)\n",
    "\n",
    "    # Get the DAG\n",
    "    pred_dag = model.causal_matrix\n",
    "    \n",
    "    # Get learned graph\n",
    "    learned_graph = nx.DiGraph(pred_dag)\n",
    "\n",
    "    # Relabel the nodes\n",
    "    MAPPING = {k: v for k, v in zip(range(5), ['Destination Type', 'Alternative Flights', 'Flight Price', 'dtg', 'CvR'])}\n",
    "\n",
    "    learned_graph = nx.relabel_nodes(learned_graph, MAPPING, copy=True)\n",
    "    # Plot the graph\n",
    "    nx.draw_networkx(\n",
    "        learned_graph,\n",
    "        with_labels=True,\n",
    "        node_size=1800,\n",
    "        font_size=8,\n",
    "        font_color='black'\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
